{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI 670 Kaggle Competition, Team 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets and Preprocess\n",
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")\n",
    "\n",
    "train['ind'] = train['references'].map(lambda x: x!=x)*1\n",
    "train.loc[train['ind']==1,'references'] = ''\n",
    "test['ind'] = test['references'].map(lambda x: x!=x)*1\n",
    "test.loc[test['ind']==1,'references'] = ''\n",
    "\n",
    "train['tit_len']=train['title'].map(lambda x: len(x.split()))\n",
    "train['abs_len']=train['abstract'].map(lambda x: len(x.split()))\n",
    "train['ref_len']=train['references'].map(lambda x: len(x.split()))\n",
    "test['tit_len']=test['title'].map(lambda x: len(x.split()))\n",
    "test['abs_len']=test['abstract'].map(lambda x: len(x.split()))\n",
    "test['ref_len']=test['references'].map(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.loc[:,train.columns!='label'], train['label'], test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b',sublinear_tf=True,min_df=5)\n",
    "tit_train_train=vectorizer.fit_transform(X_train[\"title\"])\n",
    "tit_train_test=vectorizer.transform(X_test[\"title\"])\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b',sublinear_tf=True,min_df=5)\n",
    "abs_train_train=vectorizer.fit_transform(X_train[\"abstract\"])\n",
    "abs_train_test=vectorizer.transform(X_test[\"abstract\"])\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b',sublinear_tf=True,min_df=5)\n",
    "ref_train_train=vectorizer.fit_transform(X_train[\"references\"])\n",
    "ref_train_test=vectorizer.transform(X_test[\"references\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the corresponding columns from title, abstract and references\n",
    "tit_abs_ref_train=hstack((tit_train_train,abs_train_train,ref_train_train))\n",
    "tit_abs_ref_test=hstack((tit_train_test,abs_train_test,ref_train_test))\n",
    "X_train = hstack((tit_abs_ref_train,X_train[['year','n_citation','ind','tit_len','abs_len','ref_len']].reset_index(drop=True)))\n",
    "X_test = hstack((tit_abs_ref_test,X_test[['year','n_citation','ind','tit_len','abs_len','ref_len']].reset_index(drop=True)))\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and parameter choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## use cross-validation to choose alpha\n",
    "for alpha in [4,5,6,7]:\n",
    "    for tol in [0.0001,0.001,0.01,0.1,1]:\n",
    "        clf = RidgeClassifier(alpha=alpha,normalize=True,solver=\"sparse_cg\",tol=tol)\n",
    "        cvs = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "        print([cvs,np.mean(cvs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeClassifier(alpha=5,normalize=True,solver=\"sparse_cg\",tol=0.1).fit(X_train,y_train)\n",
    "print(clf.score(X_train,y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bagging:\n",
    "ridge_lst = []\n",
    "for i in range(10):\n",
    "    tryind = np.random.choice(X_train.shape[0],X_train.shape[0])\n",
    "    clf = RidgeClassifier(alpha=5,normalize=True,solver=\"sparse_cg\",tol=0.1).fit(X_train.tocsr()[tryind,:],y_train[tryind])\n",
    "    ridge_lst.append(clf.predict(X_test))\n",
    "np.mean(pd.DataFrame(ridge_lst).T.mode(axis=1)[0]==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##random:\n",
    "ridge_lst = []\n",
    "for i in range(10):\n",
    "    trycol = np.random.choice(X_train.shape[1],20000)\n",
    "    tryrow = np.random.choice(X_train.shape[0],X_train.shape[0])\n",
    "    clf = RidgeClassifier(alpha=5,normalize=True,solver=\"sparse_cg\",tol=0.1).fit(X_train.tocsr()[:,trycol][tryrow,:],y_train[tryrow])\n",
    "    ridge_lst.append(clf.predict(X_test.tocsr()[:,trycol]))\n",
    "np.mean(pd.DataFrame(ridge_lst).T.mode(axis=1)[0]==y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b',sublinear_tf=True,min_df=5)\n",
    "tit_train=vectorizer.fit_transform(train[\"title\"])\n",
    "tit_test=vectorizer.transform(test[\"title\"])\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b',sublinear_tf=True,min_df=5)\n",
    "abs_train=vectorizer.fit_transform(train[\"abstract\"])\n",
    "abs_test=vectorizer.transform(test[\"abstract\"])\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b',sublinear_tf=True,min_df=5)\n",
    "ref_train=vectorizer.fit_transform(train[\"references\"])\n",
    "ref_test=vectorizer.transform(test[\"references\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tit_abs_ref_train0=hstack((tit_train,abs_train,ref_train))\n",
    "tit_abs_ref_test0=hstack((tit_test,abs_test,ref_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate the final datasets\n",
    "train_x_new = hstack((train[['year','n_citation','ind','tit_len','abs_len','ref_len']],tit_abs_ref_train0))\n",
    "train_y = train['label']\n",
    "test_x_new = hstack((test[['year','n_citation','ind','tit_len','abs_len','ref_len']],tit_abs_ref_test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeClassifier(alpha=5,normalize=True,solver=\"sparse_cg\",tol=0.1).fit(train_x_new,train_y)\n",
    "print(clf.score(train_x_new,train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict and Output\n",
    "pd.DataFrame({'Id': range(29809),'Category': clf.predict(test_x_new)}).to_csv(\"output11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.loc[:,train.columns!='label'], train['label'], test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tf-idf encoding\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b',max_features=4645,sublinear_tf=True,min_df=5) #ngram_range=(1,3)\n",
    "tit_train_train=pd.DataFrame(vectorizer.fit_transform(X_train[\"title\"]).toarray())\n",
    "tit_train_train.columns=[x+'_tit' for x in vectorizer.get_feature_names()]\n",
    "tit_train_test=pd.DataFrame(vectorizer.transform(X_test['title']).toarray())\n",
    "tit_train_test.columns=tit_train_train.columns\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b',max_features=15000,sublinear_tf=True,min_df=5)\n",
    "abs_train_train=pd.DataFrame(vectorizer.fit_transform(X_train[\"abstract\"]).toarray())\n",
    "abs_train_train.columns=[x+'_abs' for x in vectorizer.get_feature_names()]\n",
    "abs_train_test=pd.DataFrame(vectorizer.transform(X_test['abstract']).toarray())\n",
    "abs_train_test.columns=abs_train_train.columns\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b',max_features=15000,sublinear_tf=True,min_df=5)\n",
    "ref_train_train=pd.DataFrame(vectorizer.fit_transform(X_train[\"references\"]).toarray())\n",
    "ref_train_train.columns=[x+'_ref' for x in vectorizer.get_feature_names()]\n",
    "ref_train_test=pd.DataFrame(vectorizer.transform(X_test['references']).toarray())\n",
    "ref_train_test.columns=ref_train_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the corresponding columns from title, abstract and references\n",
    "tit_abs_ref_train=pd.concat([tit_train_train,abs_train_train,ref_train_train],axis=1)\n",
    "tit_abs_ref_test=pd.concat([tit_train_test,abs_train_test,ref_train_test],axis=1)\n",
    "## Chi2 select\n",
    "chi2_f = SelectKBest(score_func=chi2, k = 300) \n",
    "X_kbest = chi2_f.fit(tit_abs_ref_train,y_train)\n",
    "ind_tit_abs_ref=[X_kbest.scores_.tolist().index(x) for x in sorted(X_kbest.scores_,reverse=True)[0:30000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select 30000 variables with the best 30000 chi2 and Generate the needed datasets\n",
    "X_train = pd.concat([X_train[['year','n_citation','ind','tit_len','abs_len','ref_len']].reset_index(drop=True),tit_abs_ref_train.iloc[:,ind_tit_abs_ref]],axis=1)\n",
    "X_test = pd.concat([X_test[['year','n_citation','ind','tit_len','abs_len','ref_len']].reset_index(drop=True),tit_abs_ref_test.iloc[:,ind_tit_abs_ref]],axis=1)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select all the variables and Generate the needed datasets\n",
    "X_train = pd.concat([X_train[['year','n_citation','ind','tit_len','abs_len','ref_len']].reset_index(drop=True),tit_abs_ref_train],axis=1)\n",
    "X_test = pd.concat([X_test[['year','n_citation','ind','tit_len','abs_len','ref_len']].reset_index(drop=True),tit_abs_ref_test],axis=1)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Minmax-scale the datasets for some methods\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model & Parameter choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge: Compare cross validation score for datasets with small p\n",
    "for i in [2,3,4,5]:\n",
    "    ridge = RidgeClassifier(alpha=i,normalize=True)\n",
    "    cvs = cross_val_score(ridge, X_train, y_train, cv=5)\n",
    "    print([cvs,np.mean(cvs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge: Compare one-split score for datasets with large p\n",
    "for i in [1.5,2,3,4,5,6,7]:\n",
    "    clf = RidgeClassifier(alpha=i,normalize=True).fit(X_train,y_train)\n",
    "    print(clf.score(X_train,y_train))\n",
    "    print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Records\n",
    "## 8000:\n",
    "alpha=1.5 0.9300121608588082,0.8906407245890641\n",
    "alpha=2 0.9258187612697614,0.8911439114391144\n",
    "alpha=3 0.9206608797752338,0.8918148272391815\n",
    "alpha=4 0.9173900280957773,0.8916470982891647\n",
    "## 9000:\n",
    "alpha=2 0.9303056988300415,0.8916470982891647\n",
    "alpha=3 0.9246446093848283,0.891479369339148\n",
    "## 15000:\n",
    "alpha=1.5 0.9552983603807607,0.8898020798389802\n",
    "alpha=2 0.9494276009560951,0.8918148272391815\n",
    "alpha=3 0.9403698578437539,0.8934921167393493\n",
    "alpha=3.6 0.9367635341971736,0.8934921167393493\n",
    "alpha=4 0.9346668344026502,0.8934921167393493\n",
    "alpha=4.1 0.9343313624355265,0.8933243877893324\n",
    "alpha=4.5 0.9329894745670315,0.8926534719892654\n",
    "alpha=5 0.9307250387889462,0.8918148272391815\n",
    "## 25000:\n",
    "alpha=4 0.9544596804629513 0.8956725930895673\n",
    "alpha=5 0.9488405250136286 0.8960080509896008\n",
    "alpha=6 0.9447729274122532 0.8950016772895002\n",
    "alpha=7 0.941544009728687 0.8950016772895002\n",
    "## 30000:\n",
    "alpha=4 0.9617142617520024 0.8958403220395841\n",
    "alpha=5 0.95613704029857 0.8961757799396176\n",
    "alpha=6 0.9526565186396612 0.8960080509896008\n",
    "alpha=7 0.9486727890300667 0.8948339483394834\n",
    "## 35000:\n",
    "alpha=5 0.9623432716903594 0.8960080509896008\n",
    "alpha=6 0.9584434100725459 0.8960080509896008\n",
    "alpha=7 0.9546274164465132 0.8948339483394834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bagging\n",
    "ridge_lst = []\n",
    "for i in range(3):\n",
    "    tryind = np.random.choice(X_train.shape[0],X_train.shape[0])\n",
    "    clf = RidgeClassifier(alpha=2,normalize=True).fit(X_train.iloc[tryind,:],y_train[tryind])\n",
    "    print(clf.score(X_test, y_test))\n",
    "    ridge_lst.append(clf.predict(X_test))\n",
    "np.mean(pd.DataFrame(ridge_lst).T.mode(axis=1)[0]==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random\n",
    "ridge_lst = []\n",
    "for i in range(50):\n",
    "    trycol = np.random.choice(X_train.shape[1],5000)\n",
    "    tryrow = np.random.choice(X_train.shape[0],X_train.shape[0])\n",
    "    clf = RidgeClassifier(alpha=2,normalize=True).fit(X_train.iloc[tryrow,trycol],y_train[tryrow])\n",
    "    #print(clf.score(X_test.iloc[:,trycol], y_test))\n",
    "    ridge_lst.append(clf.predict(X_test.iloc[:,trycol]))\n",
    "np.mean(pd.DataFrame(ridge_lst).T.mode(axis=1)[0]==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try other methods, not as ideal as Ridge\n",
    "### Linear SVC\n",
    "lclf = LinearSVC(C=0.01).fit(X_train_scaled, y_train)\n",
    "lclf.score(X_train_scaled, y_train),lclf.score(X_test_scaled, y_test)\n",
    "### SGD\n",
    "sgd = SGDClassifier(alpha=0.002,penalty='l2',loss='log').fit(X_train_scaled, y_train)\n",
    "sgd.score(X_train_scaled, y_train),sgd.score(X_test_scaled, y_test)\n",
    "### Logistic\n",
    "lr = LogisticRegression(C=1).fit(X_train_scaled, y_train)\n",
    "lr.score(X_train_scaled, y_train),lr.score(X_test_scaled, y_test)\n",
    "### Multinomial Naive Bayes\n",
    "mnb=MultinomialNB(alpha=0.5).fit(X_train_scaled, y_train)\n",
    "mnb.score(X_train_scaled, y_train),mnb.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tf-idf encoding\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b',max_features=5000,sublinear_tf=True,min_df=5)\n",
    "tit_train=pd.DataFrame(vectorizer.fit_transform(train[\"title\"]).toarray())\n",
    "tit_train.columns=[x+'_tit' for x in vectorizer.get_feature_names()]\n",
    "tit_test=pd.DataFrame(vectorizer.transform(test['title']).toarray())\n",
    "tit_test.columns=tit_train.columns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b',max_features=15000,sublinear_tf=True,min_df=5) #\n",
    "abs_train=pd.DataFrame(vectorizer.fit_transform(train[\"abstract\"]).toarray())\n",
    "abs_train.columns=[x+'_abs' for x in vectorizer.get_feature_names()]\n",
    "abs_test=pd.DataFrame(vectorizer.transform(test['abstract']).toarray())\n",
    "abs_test.columns=abs_train.columns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b',max_features=15000,sublinear_tf=True,min_df=5)\n",
    "ref_train=pd.DataFrame(vectorizer.fit_transform(train[\"references\"]).toarray())\n",
    "ref_train.columns=[x+'_ref' for x in vectorizer.get_feature_names()]\n",
    "ref_test=pd.DataFrame(vectorizer.transform(test['references']).toarray())\n",
    "ref_test.columns=ref_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the corresponding columns from title, abstract and references\n",
    "tit_abs_ref_train0=pd.concat([tit_train,abs_train,ref_train],axis=1)\n",
    "tit_abs_ref_test0=pd.concat([tit_test,abs_test,ref_test],axis=1)\n",
    "## chi2 select\n",
    "chi2_f = SelectKBest(score_func=chi2, k = 300) \n",
    "X_kbest = chi2_f.fit(tit_abs_ref_train0,train['label'])\n",
    "ind_tit_abs_ref0=[X_kbest.scores_.tolist().index(x) for x in sorted(X_kbest.scores_,reverse=True)[0:30000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate the final datasets\n",
    "train_x_new = pd.concat([train[['year','n_citation','ind','tit_len','abs_len','ref_len']],tit_abs_ref_train0.iloc[:,ind_tit_abs_ref0]],axis=1)\n",
    "train_y = train['label']\n",
    "test_x_new = pd.concat([test[['year','n_citation','ind','tit_len','abs_len','ref_len']],tit_abs_ref_test0.iloc[:,ind_tit_abs_ref0]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit model using the parameter chosen before\n",
    "clf = RidgeClassifier(alpha=5,normalize=True).fit(train_x_new,train_y)\n",
    "print(clf.score(train_x_new,train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict and Output\n",
    "pd.DataFrame({'Id': range(29809),'Category': clf.predict(test_x_new)}).to_csv(\"output10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "si670f19_lab_1_ans.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
